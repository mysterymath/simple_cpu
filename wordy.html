<!doctype html>
<html lang="en-US">
<title>A Simple CPU</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<style>
    html {
        background-color: #002b36;
    }
    .content {
        color: #839496;
	      font-family: Georgia, serif;
        line-height: 1.5;
        max-width: 60ch;
        margin-left: auto;
        margin-right: auto;
    }
    h1,h2,h3,h4,h5,h6 {
        color: #93a1a1;
	      font-family: sans-serif;
        line-height: normal;
    }
    p,ul,ol {
        break-inside: avoid;
    }
    a:link {
      color: #268bd2;
    }
    a:visited {
      color: #d33682;
    }
    code {
      font-size: large;
    }
    .not {
      text-decoration: overline;
    }
</style>
<div class="content">
<h1>A Simple CPU</h1>
<h2>What Does it Take?</h2>
<p>If I wanted to make a CPU "from scratch," what would it take? What is the
simplest CPU that I can build? Inspired by <i><a
href="http://www.thetoasterproject.org">The Toaster Project</a></i>, I've
been exploring this question.

<p>"From scratch" and "simplest" are both rather vague. Depending on
interpretation, they could range anywhere from mining copper (hats off to
you, Toaster Guy) to buying a CPU off the shelf. If the task is too easy, it
won't feel satisfying. Too hard and it's not achievable at all. Some ground
rules seem in order.

<p>Making a "simplest" anything almost necessarily involves the most
gratiutous allowable abuse of the rules. Accordingly, the rules will control
a great deal of the project's nature. After carefully examining the
consequences of various rule sets, I've chosen the following:
<ul>
    <li>The CPU should be integrable in a "real system". Together they should
    be capable of doing usual computer things like I/O, addition,
    subtraction, etc.
    <li>Any parts of the CPU purchased from the store must not be specifically intended
    for inclusion in a CPU. This precludes purchasing ALUs and the like.
    <li>No FPGAs, CPLDs or the like in the CPU. Purchased parts must be
    limited in the sorts of functions they be made to directly compute.
    Otherwise this becomes "just another FPGA CPU project."
    <li>The CPU must be responsible for the overall control of the system.
    <li>The CPU should use as few components and wires as possible.
</ul>

<p>What exactly does a CPU do? Well, a CPU reads an instruction from the
system, then does whatever it says. Some instructions may involve obtaining
additional information from the system, delivering information to the system,
or both.

<h2>Abstract Communciations</h2>
<p>The CPU needs to be able to read/write main memory and to perform I/O. Via
the <a href="https://en.wikipedia.org/wiki/Memory-mapped_I/O">memory mapped
I/O</a> approach, certain address regions can be reserved for I/O devices,
with the rest mapping to main memory. I/O devices themselves answer reads and
writes for these regions, and various combinations of reads and writes
correspond to the avialable I/O operations. This allows one mechanism to be
used for all CPU/system communications. Nice and simple for the CPU (although
maybe less so for the I/O devices).

<p>The address space should be 8-bit byte-addressable, since that's long been
the standard. How big should addresses be? A multiple of 8 bits would allow
them to be stored in RAM without waste. 8-bit addresses would only allow 256
addressable bytes, but 16-bit addresses work just fine, allowing 64KiB of
address space. The addresses are stored big-endian, since that's what the
chips used in the implementation expect.

<h2>Instruction Set</h2>
<p> How many different kinds of operations does the CPU need to be able to
perform? If the goal is to be as simple as possible, only one. There are a
dazzling variety of <a
href="https://en.wikipedia.org/wiki/One_instruction_set_computer">one
instruction set computer</a> (OISC) architectures, where the computer has exactly
one way of interacting with the rest of the system. By the magic of
Turing-equivalency, any such processor is able to simulate far more rich
instruction sets, just by repeating that one interaction ad infinitum.

<p>Of all the OISC available, which is simplest to implement? Our chosen
communication scheme suggests a natural answer: <a
href="https://esolangs.org/wiki/ByteByteJump">byte byte jump</a>. This OISC
consists exclusively of the two basic communication operations: read and
write.

<p>A byte byte jump instruction contains the following 48-bits:
<ul>
    <li>A 16-bit source address
    <li>A 16-bit destination address
    <li>A 16-bit jump address
</ul>

<p>A CPU implementing byte byte jump would do the following repeatedly:
<ol>
    <li>Read the source, destination and jump addresses at the CPU's instruction pointer.
    <li>Read the byte at the source address and write it to the destination address.
    <li>Change the processor's instruction pointer to the jump address.
</ol>

<p>That's it! A CPU that can do the above can compute any computable
function. It's not an ivory tower theoretical "can" either; the reduction is
surprisingly practical (for a hilariously impractical value of practical).

<h2>Synthesizing Addition: <a href="https://en.wikipedia.org/wiki/IBM_1620">Can't Add, Doesn't Even Try</a></h2>
<p>To provide an intuition of how computation can be done with just a
glorified move instruction, I'll sketch some of the strategies used to
construct an 8-bit addition operation using only byte byte jump. I'll spare
the details, as the actual construction of such an operation is a bit
intricate, and most of it is not difficult or interesting, but just tedious.

<p>How might one go about constructing addition? Well, imagine we have a
"giant" table that takes up the entire 64KiB address space. Such a table
could be indexed by a pair of 8 bit values; one forming the high byte of the
value, and the other forming the low byte. In such a table, we could just
store the sum of the two indices; an indexed lookup into this table would
allow adding any two 8-bit values.

<p>Unfortunately, this wouldn't leave room in the address space for anything
else. But this is just a matter of size. The complete table of 4-bit by 4-bit
sums occupies only 256 addresses. This leads to a workable approach: do two
separate 4-bit additions, one between the low 4 bits of the input bytes, and
another between the high 4 bits. Incorporate the carry from the low addition
into the high one, and combine the two sums together into a full 8-bit
addition. This can be all accomplished by a series of subsequent lookups in
around 5KiB of tables included with the program.

<p>Given one of these tables, how can byte byte jump perform a lookup? On the
face of it, it seems like the source and destination addresses for any given
instruction are fixed. The trick is an old one: self-modifying code. Either
or both byte of the source address can be overwritten by a prior move
instruction. Specifically, if a table ranges from $xy00 to $xyFF, then
overwriting the low byte of the source address with the offset causes the
next instruction to perform an indexed lookup in that table.

<p>Conditional branches and the like can be achieved using a similar trick,
instead overwriting the jump part of the address instead of the source.

<p>The above technique works byte at a time, which gives obvious access to
two table sizes: 8-bit and 16-bit. However, no 16-bit tables can be used,
since they would consume the entire address space, leaving no room for the
program. A 12-bit table only occupies 4KiB of the address space, which is
quite practical, and it would allow combining 4 bits of one index byte with
all 8 bits of another. This is the only way I could find for this
architecture to do a lookup that depended on more than one byte. This is
quite indispensible for doing addition, since our approach depends on adding
parts of two different bytes together.

<p>The trick is, of course, another table: this time to generate the high
byte of a 16-bit indexed lookup. The observation is that since we want 12-bit
tables, only the low 4 bits of the high byte should be allowed to vary with
the index. Another 8-bit table can overwrite the high 4 bits of any byte with
the highest 4 bits of the table address. This allows the low 4 bits of any
byte to offset a lookup in a 4096-byte table.

<p>Addition tables like the one used here are not purely theoretical; the
approach was used in at least one production computer. The <a
href="https://en.wikipedia.org/wiki/IBM_1620">IBM 1620</a> was codenamed
CADET during devolpment; some in the user community suggested that this
acronym stood for "Can't Add, Doesn't Even Try". But, even machines like
these can't add, they sure do a good impression of those that can!

<h2>CPU Registers</h2>

<p>What would a hardware implementation of byte byte jump look like? Recall
the definition of the operation:

<ol>
    <li>Read the source, destination and jump addresses at the CPU's instruction pointer.
    <li>Read the byte at the source address and write it to the destination address.
    <li>Change the processor's instruction pointer to the jump address.
</ol>

<p>Incorporating a bit more detail into how the CPU communicates with the
system gives the following:

<ol>
    <li>Execute a system read operation using the CPU's instruction pointer.
    Save the 48 bits read from the system somewhere inside the processor.
    Store some of the bits as the new instruction pointer, and the others in
    CPU registers for the source and destination addresses.
    <li>Execute a system read operation at the source address, and save next
    8 bits in a location for the source value.
    <li>Execute a system write operation at the destination address and
    provide the 8 source value bits.
</ol>

<p>In the above, assume that the system can provide more than one byte's
worth of data per read. This simplifies things quite a bit, since there's no
need for the CPU to contain counting logic to generate subsequent addresses.
All of the provided address can be regurgitated back from the exact values
provided by the system.

<p>To produce the above set of reads and writes, the CPU needs to remember
around 56 bits of information. Tweaking the set of reads and writes can
probably bring this number down, but not any lower than 32, since the CPU
must maintain its instruction pointer at all times, and any read or write
requires remembering the 16-bit address. Right off the bat, if the CPU's
registers are accessed in a parallel fashion, we'll need at least 16 wires to
connect things up. Tons of breadboard space, tons of wires and connections to
route. Yuck, not simple.

<p>Instead of using parallel access then, how about serial? If the system
sends and receives data one bit at a time, then the CPU could do the same for
its internal storage. This would allow all 56 bits to be sent and received
over the same wire, just at different times, and the CPU could pass the
serial signal through to a serial storage chip inside itself. Seems like it
might be simpler.

<h2>Register Shopping</h2>

<p>So, we're now looking for a memory or register chip that communicates in a
serial fashion. To the store! I'll use <a
href="https://mouser.com">Mouser</a>, since I like their product filtering
UI. The chip needs to communicate serially, operate at 3.3 V, and ideally be
as cheap as possible. Oh, and mount using through-hole pins, so they're easy
to put on a breadboard.

<p>The cheapest memory chips there are EEPROM chips, but these are difficult
and slow to write to. We can filter those out. After that, the cheapest are
Flash chips; these are just fancy EEPROMs. To the bin with you!

<p>After filtering the various ROMs out, the next cheapest chip is the <a
href="https://www.microchip.com/wwwproducts/en/23K640">Microchip
23K640-I/P</a> 64KBit SRAM. This one communicates using the <a
href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface">Serial
Peripheral Interface</a> (SPI). SPI is just about the simplest serial
communications protocol I can imagine; this bodes well.

<h2>Microchip SRAM</h2>
<p>Looking at the <a
href="http://ww1.microchip.com/downloads/en/DeviceDoc/22126E.pdf">data
sheet</a> for this chip, the chip has 7 connected pins; that's good, not too
much to wire up. Besides power and ground, this leaves 5 data pins: <span
class="not">CS</span>, <span class="not">HOLD</span>, SCK, SI, and SO. The
overline indicates that the pin is "active" when it sees ground, not power. We say
that power voltage is "high" and that ground voltage is "low"; thus overlined pins
are "active low."

<p>During normal operation, shortly after SCK (serial clock) goes from ground
voltage (high) to power voltage, the chip samples the voltage level of the SI
(serial input) pin. If the voltage level is power, the chip considers itself
to have read a one; ground, a zero. Shortly after SCK returns from power
voltage to ground voltage, the chip has the opportunity to output a bit on
SO. It does so by internally connecting SO to either power for a one or
ground for a zero. If it does not desire to output a bit, it leaves SO
disconnected.

<p>In the usual configuration SCK is always ticking, but a read or write
needs to have a definite beginning and ending. This is the purpose of the
<span class="not">CS</span> (chip select) pin. When <span
class="not">CS</span> is high, the chip is blind to SCK ticks, and SO is
disconnected. When <span class="not">CS</span> transitions from high to low,
the chip considers an operation to have begun; when <span
class="not">CS</span> transitions back from low to high, the operation ends.
All values sent in and out of the chip are most-significant-bit first.

<p>There are two basic operation cycles: read and write. A read operation
consists of clocking 00000011 to the chip, then the 16-bit address.
Afterwards, the chip will clock the byte at that address to SO. By
default, it's unspecified what happens if the operation is not immediately
ended after one byte.

<p>A write operation consists of clocking 00000010 to the chip, then the
16-bit address, then the byte to write. By default, it's unspecified what
happens if the operation is not immediately ended after one byte.

<p>Writing one byte at a time isn't exactly ideal, since we'd need the
aforementioned counting mechanism to generate successive accesses. Luckily,
the chip provides a "sequential mode", which operates very much as we'd
desire. In sequential mode, as many bytes as desired can be read or written
by continuing the operation after the first bytes. The chip does not
initialize in sequential mode however; an operation needs to be executed to
place the chip in this mode.

<p>Man, wouldn't it be nice if the chip started in sequential mode? Then we
wouldn't have to deal with this extra operation; just read and write. Well,
if we go a bit up in Microchip's SRAM product line to the 23LC512, we find a
512KBit (64KiB) SRAM that operations almost identically to the 23K640. This
larger chip defaults to sequential mode, and still only costs around a buck!

<h3>Aside</h3>

<p>I'll pause for a moment to revel in the decision to use a 64KiB SRAM to
store 56 bits of data inside a CPU. This chip probably has far more switching
elements in it than the first 100 computers built by man. Still, the magic of
VLSI makes this the simplest and most cost effective option for this storage.

<p>Though this chip does have an instruction set and sequential control
logic for executing it, it's far from Turing complete on its own. It doesn't
have the, for lack of a better word, recursiveness required for general
computation. Our goal will then be to bless it with this recursiveness, by
reflecting some aspects of its own operation back at it, to turn it from a
simple RAM chip into a fully fledged CPU.

<h2>Control</h2>

<p>Now that we have a real chip to work with, we can recast the orignal list of
tasks in its terms:

<ol>
  <li>Read the instruction.
    <ol>
        <li>Activate chip. Begin system read.
        <li>Send 00000011 (read) to SI.
        <li>Send the instruction pointer's address in the register memory to SI.
        <li>The chip sends the instruction pointer to the system via SO.
        <li>Deactivate chip.
        <li>Activate chip.
        <li>Send 00000010 (write) to SI.
        <li>Send the address that will receive the instruction to SI. The jump
        address overlaps the instruction pointer in the SRAM.
        <li>The system sends 48 bits of data to the chip via SI. This overwrites
        the instruction pointer as well.
        <li>End system read. Deactivate chip.
    </ol>
  <li>Read the value at the source address.
    <ol>
      <li>Activate chip. Begin system read.
      <li>Send 00000011 (read) to SI.
      <li>Send the source address's address in the register memory to SI.
      <li>The chip sends the source address to the system via SO.
      <li>Deactivate chip.
      <li>Activate chip.
      <li>Send 00000010 (write) to SI.
      <li>Send the address that will receive the source value to SI.
      <li>The system sends 8 bits of data to the chip via SI.
      <li>End system read. Deactivate chip.
    </ol>
  <li>Store the value at the destination address.
    <ol>
      <li>Activate chip. Begin system write.
      <li>Send 00000011 (read) to SI.
      <li>Send the destination address's address in the register memory to SI.
      <li>The chip sends the destination address to the system via SO.
      <li>Deactivate chip.
      <li>Activate chip.
      <li>Send 00000011 (read) to SI.
      <li>Send the address that received the source value to SI.
      <li>The chip sends 8 bits of data to the system via SO.
      <li>End system write. Deactivate chip.
    </ol>
</ol>

<p>Some immediate observations spring from the above breakdown. First, SI and
SO never have signals sent across them at the same time. This means they can
be physically connected together into one SIO signal; this is referred to as
"three wire SPI." This means all data passes over one wire, whether driven by
control, the bus, or the SRAM chip.

<p>Next, the layout of the SRAM and instruction can be specified. For
simplicity, let's begin the used region of the SRAM at address zero. The
instruction pointer is the first value accessed, so place that at zero. Then,
beginning each instruction with the instruction pointer establishes the
overlap criterion of 1.8 and 1.9. If the value ends with the destination
address, then the value location can follow immediately afterwards. This
saves the second read cycle at 3.7, which can be skipped by allowing the chip
to read from the destination address straight through to the value. Thus
addresses in the instruction are ordered jump, source, destination.

<p>No explicit mechanism for controlling the system bus has been established.
We can crib a simplified mechanism for this from our SRAM. Give the system
bus an active low select line, just like the chip. Read and write operations
work exactly as on the chip, except a read is signalled by writing a 0, and a
write by writing a 1.

<p>Putting that all together, we get the following:

<ol>
  <li>Read the instruction.
    <ol>
        <li>Activate system.
        <li>Send 0.
        <li>Activate chip.
        <li>Send 00000011 00000000 00000000.
        <li>The chip sends the instruction pointer.
        <li>Deactivate chip.
        <li>Activate chip.
        <li>Send 00000010 00000000 00000000.
        <li>The system sends 48 bits of data.
        <li>Deactivate system. Deactivate chip.
    </ol>
  <li>Read the value at the source address.
    <ol>
      <li>Activate system.
      <li>Send 0.
      <li>Activate chip.
      <li>Send 00000011 00000000 00000010.
      <li>The chip sends the source address.
      <li>Deactivate chip.
      <li>Activate chip.
      <li>Send 00000010 00000000 00000110.
      <li>The system sends 8 bits of data.
      <li>Deactivate system. Deactivate chip.
    </ol>
  <li>Store the value at the destination address.
    <ol>
      <li>Activate system.
      <li>Send 1.
      <li>Activate chip.
      <li>Send 00000011 00000000 00000100.
      <li>The chip sends 24 bits of data.
      <li>Deactivate system. Deactivate chip.
    </ol>
</ol>

<p>A few more observations. First, there are three ways that SIO can be driven:
<ol>
  <li>The control system drives SIO, like in 1.2 and 1.4
  <li>The SRAM chip drives SIO, like in 1.5
  <li>The system drives SIO, like in  1.9
</ol>

<p>What happens if more than one of these sources drive SIO at the same time?
Well, recall that SIO is driven by either connecting it to power or to
ground. If all driving sources write the same value, nothing usual happens.
But if SIO is connected to both power and ground simultaneously, this creates
a short circuit between power and ground. A large amount of current can flow,
generating a lot of waste power and potentially frying the chips, the
Raspberry PI, or both. This situation needs to be avoided.

<p>The system only writes to SIO if the SRAM is accepting input from SIO, and
vice versa. Thus these two devices can never write conflicting bits to SIO,
since neither can write and listen simultaneously. How about the control
signals? These drive SIO one moment (1.4), but stop the next (1.5). The
control behavior of SIO can be described by 2 bits: one that determines
whether control is driving SIO, and one that determines the value if control
is driving SIO. If the first bit is zero, the second doesn't matter.

<p>Finally, note the oddity of the system's timing for reads and writes. The
read tag comes in at 1.2, but the address doesn't come in until 25 clocks
later at 1.5. The read values are delayed for 26 clocks until 1.9. However,
note that exactly the same timing holds for the read at 2.2. The rules don't
specify how system reads and writes need to happen; they can be as odd as we
like. Odd timings also don't encode too much of the CPU's behavior into the
system bus protocol; it's easy to imagine a different CPU than this one with
more sophisticated control logic communicating across the same bus.

<p>Putting that all together, we get the full set of control signals for the
processor cycle. The whole thing takes around 250 clock cycles to execute a
byte byte jump.

<ol>
  <li>Read the instruction.
    <ol>
        <li>Activate system.
        <li>Control begins driving SIO. Send 0.
        <li>Activate chip.
        <li>Send 00000011 00000000 00000000.
        <li>Control stops driving SIO for 16 bits.
        <li>Deactivate chip.
        <li>Activate chip.
        <li>Control starts driving SIO. Send 00000010 00000000 00000000.
        <li>The system sends 48 bits of data.
        <li>Deactivate system. Deactivate chip.
    </ol>
  <li>Read the value at the source address.
    <ol>
      <li>Activate system.
      <li>Send 0.
      <li>Activate chip.
      <li>Send 00000011 00000000 00000010.
      <li>The chip sends the source address.
      <li>Deactivate chip.
      <li>Activate chip.
      <li>Send 00000010 00000000 00000110.
      <li>The system sends 8 bits of data.
      <li>Deactivate system. Deactivate chip.
    </ol>
  <li>Store the value at the destination address.
    <ol>
      <li>Activate system.
      <li>Send 1.
      <li>Activate chip.
      <li>Send 00000011 00000000 00000100.
      <li>The chip sends 24 bits of data.
      <li>Deactivate system. Deactivate chip.
    </ol>
</ol>

<h2>Control EEPROMs</h2>

<p>There are 4 control signals in the above cycle: SRAM chip select, system chip
select, SIO, and SIO control activation. If they are repeated indefinitely,
then the SRAM will perform a series of byte byte jump operations, operating
as a CPU. So how can these sequences be generated?

<p>Well, our SRAM chip is awfully good at generating a sequence of bits in
sequential mode. If the whole SRAM were filled with control sequences and a
read were issued at zero, the control sequences would be read out on SO until
the end of the RAM were reached. At that point, the datasheet says that the
internal address pointer wraps around to zero. This means if we can get the
control signals to fill the entire RAM, we can generate those signals
indefinitely using 4 additional SRAMs.

<p>Using SRAMs for this is rather inconvenient though, since on power up their
state is random. What we need is an EEPROM chip that works just like our SRAM
chip. Conveniently, Microchip manufactures one: the Microchip <a
href="https://www.microchip.com/wwwproducts/en/25LC010A">25LC010A</a>
1024-bit EEPROM. It even defaults to sequential mode, just like the SRAM
does. With 4 of these, we can generate all 4 control signals.

<p>The SO pins of the EEPROMs for the SRAM <span class="not">CS</span> and
system <span class="not">CS</span> can be directly connected to their
respective pins. The EEPROMs can be clocked by SCLK; shortly after SCLK goes
low, the next bit of signal will be driven on these pins. Thus the activation
lines go low before the first bit of input indicated by the next rising clock
edge, and they go back high after the last bit of input. So far so good.

<p>If we were to directly connect an EEPROM to the SIO line, this would
always drive that line; the system and SRAM chip would never get a turn to
speak. Still, when it is the control's turn to speak, this arrangement does
produce the correct signal. What remains is some way to disable the SIO EEPROM
and reenable it temporarily.

<p>The EEPROM's <span class="not">HOLD</span> pin allows us to do just that.
Setting this pin low accomplishes two things. First, shortly afterwards, the
EEPROM stops driving it's SO pin. Second, the chip becomes insensitive to
clock edges for as long as it is held. There is one big caveat: SCLK must
have been low for at least 80ns before <span class="not">HOLD</span> is
driven low, and <span class="not">HOLD</span> must return to high only while
SCLK is low, and at least 40ns before it goes high again. We can hook up an
EEPROM's SO to the <span class="not">HOLD</span> pin of the SIO EEPROM, but
the EEPROM datasheet does not guarantee that once the clock goes low, any
minimum amount of time will pass before the SO changes. Thus we need one
additional clock signal, HCLK, at least 80ns out of phase with SCLK. The SIO
hold EEPROM is clocked by HCLK, guaranteeing that when HCLK goes low, at
least 80ns have passed since SCLK went low. The other side of the timing
constraint is obtained by running the clocks very slowly, so there is a
relatively large amount of time between ticks.

<p>Now, the main processor cycle takes 240 cycles, so the 1024-bit EEPROMs
can contain 4 full cycles. However, the SIO EEPROM is insensitive to clock
signals while held, so it only sees 123 of these cycles. This creates a
slightly tricky situation; these two cycles need to be kept in sync across
the EEPROMS.

<p>The 123 SIO cycles will fit 4 times into 512 bits, and the main processor
cycle will fit 4 times into 1024 bits. Thus we can maintain their sync if, at
the end of every 1024-bit main cycle (once every 4 instructions), some bits
are dedicated to syncing up the SIO EEPROM to the 512-bit line.

<p>There are 512 - 4*123 = 20 bits left over on the SIO EEPROM and 1024 -
4*240 = 64 bits left over on the main EEPROMS. Thus the SIO EEPROM needs to
be held for an additional 64 - 20 = 44 cycles to sync up. These additional
hold bits can be placed anywhere within the last 64 bits of the SIO control
EEPROM.

<h2>Bootstrapping</h2>

<p>With the main loop of the CPU taken care of, there's one remaining
concern: bootstrapping. How does the CPU get into that loop in the first
place? There are two components to the answer.

<p>First, if a read is issued to any of the control EEPROMs at 0x0000, they
will continually output the desired control signal ad infinitum. Thus,
boostrapping these chips consists of the system issuing the read command when
it is brought up. This can be considered part of the responsibility of the
system, and two additional lines, B<span class="not">CS</span> and BSI can be
allocated for this purpose.

<p>Lastly, on powerup, the contents of the SRAM is nondeterministic. This
means the instruction pointer is nondeterministic, and the first instruction
will thus be read from a nondeterministic location. This could be rectified
by providing additional bootstrapping control logic as with the EEPROMs, but
there's a simpler approach. On the first read request after power on, the
system can summarily return all zeroes. This moves the SRAM into a
deterministic state and begins executing the program at location zero.

<h2>Implementation</h2>

<p>So I went to Mouser, bought 4 EEPROMs, 1 SRAM, and two pull-up resistors.
This cost me around $10 bucks or so; most of it shipping and handling.

<p>I hooked up each EEPROM in turn to my Raspberry PI, then wrote a quick
RPi.GPIO script to program them with the above control sequences via the
Raspberry PI's GPIO pins. Once each of the EEPROMs were programmed, I wired
them up to the SRAM, then wired the SCLK, HCLK, SIO, and system <span
class="not">CS</span> lines up to GPIO.

<p>I then wrote a reductuction of addition and conditional branch on zero to
byte byte jump. Afterwards it was easy to construct a simple program to print
the Fibonacci series. I implemented the system read and system write cycles
in the Raspberry PI, special casing writes to location 0xFFFF to print to the
Raspberry Pi stdout.

<p>You can see it in action below, running at various clock rates: