<!doctype html>
<title>A Simple CPU</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<style>
    html {
        background-color: #002b36;
    }
    .content {
        color: #839496;
	      font-family: Georgia, serif;
        line-height: 1.5;
        max-width: 60ch;
        margin-left: auto;
        margin-right: auto;
    }
    h1,h2,h3,h4,h5,h6 {
        color: #93a1a1;
	      font-family: sans-serif;
        line-height: normal;
    }
    p {
        break-inside: avoid;
        text-align: justify;
    }
    ul,ol {
      break-inside: avoid;
    }
    a:link {
      color: #268bd2;
    }
    a:visited {
      color: #d33682;
    }
    code, pre {
      font-size: large;
    }
    .not {
      text-decoration: overline;
    }
</style>
<div class="content">
<h1>A Simple CPU</h1>
<h2>What Does it Take?</h2>
<p>If I wanted to make a CPU "from scratch," what would it take? What is the
simplest CPU that I can build? Inspired by <i><a
href="http://www.thetoasterproject.org">The Toaster Project</a></i>, I've
been exploring this question.

<p>"From scratch" and "simplest" are both rather vague. Depending on
interpretation, they could range anywhere from mining copper (hats off to
you, Toaster Guy) to buying a CPU off the shelf. If the task is too easy, it
won't feel satisfying. Too hard and it's not achievable at all. Some ground
rules seem in order.

<p>Making a "simplest" anything almost necessarily involves the most
gratiutous allowable abuse of the rules. Accordingly, the rules will control
a great deal of the project's nature. After carefully examining the
consequences of various rule sets, I've chosen the following:
<ul>
    <li>The CPU should be integrable in a "real system". Together they should
    be capable of doing usual computer things like I/O, addition,
    subtraction, etc.
    <li>Any parts of the CPU purchased from the store must not be specifically intended
    for inclusion in a CPU. This precludes purchasing ALUs and the like.
    <li>No FPGAs, CPLDs or the like in the CPU. Purchased parts must be
    limited in the sorts of functions they be made to directly compute.
    Otherwise this becomes "just another FPGA CPU project."
    <li>The CPU must be responsible for the overall control of the system.
    <li>The CPU should use as few components and wires as possible.
</ul>

<h2>Abstract CPU Design</h2>
<p>What exactly does a CPU do? Well, a CPU reads an instruction from the
system, then does whatever it says. Some instructions may involve obtaining
additional information from the system, delivering information to the system,
or both.

<h3>Communciations</h3>
<p>The CPU needs to be able to read/write main memory and to perform I/O. Via
the <a href="https://en.wikipedia.org/wiki/Memory-mapped_I/O">memory mapped
I/O</a> approach, certain address regions can be reserved for I/O devices,
with the rest mapping to main memory. I/O devices themselves answer reads and
writes for these regions, and various combinations of reads and writes
correspond to the avialable I/O operations. This allows one mechanism to be
used for all CPU/system communications. Nice and simple for the CPU (although
maybe less so for the I/O devices).

<p>The address space should be 8-bit byte-addressable, since that's long been
the standard. How big should addresses be? A multiple of 8 bits would allow
them to be stored in RAM without waste. 8-bit addresses would only allow 256
addressable bytes, but 16-bit addresses work just fine, allowing 64KiB of
address space. The addresses are stored big-endian, since that's what the
chips used in the implementation expect.

<h3>Instruction Set</h3>
<p> How many different kinds of operations does the CPU need to be able to
perform? If the goal is to be as simple as possible, only one. There are a
dazzling variety of <a
href="https://en.wikipedia.org/wiki/One_instruction_set_computer">one
instruction set computer</a> (OISC) architectures, where the computer has exactly
one way of interacting with the rest of the system. By the magic of
Turing-equivalency, any such processor is able to simulate far more rich
instruction sets, just by repeating that one interaction ad infinitum.

<p>Of all the OISC available, which is simplest to implement? Our chosen
communication scheme suggests a natural answer: <a
href="https://esolangs.org/wiki/ByteByteJump">byte byte jump</a>. This OISC
consists exclusively of the two basic communication operations: read and
write.

<p>A byte byte jump instruction contains the following 48-bits:
<ul>
    <li>A 16-bit source address
    <li>A 16-bit destination address
    <li>A 16-bit jump address
</ul>

<p>A CPU implementing byte byte jump would do the following repeatedly:
<ol>
    <li>Read the source, destination and jump addresses at the CPU's instruction pointer.
    <li>Read the byte at the source address and write it to the destination address.
    <li>Change the processor's instruction pointer to the jump address.
</ol>

<p>That's it! A CPU that can do the above can compute any computable
function. It's not an ivory tower theoretical "can" either; the reduction is
surprisingly practical (for a hilariously impractical value of practical).

<h2>Synthesizing Addition: <a href="https://en.wikipedia.org/wiki/IBM_1620">Can't Add, Doesn't Even Try</a></h2>
<p>To provide an intuition of how computation can be done with just a
glorified move instruction, I'll sketch some of the strategies used to
construct an 8-bit addition operation using only byte byte jump. I'll spare
the details, as the actual construction of such an operation is a bit
intricate, and most of it is not difficult or interesting, but just tedious.

<p>How might one go about constructing addition? Well, imagine we have a
"giant" table that takes up the entire 64KiB address space. Such a table
could be indexed by a pair of 8 bit values; one forming the high byte of the
value, and the other forming the low byte. In such a table, we could just
store the sum of the two indices; an indexed lookup into this table would
allow adding any two 8-bit values.

<p>Unfortunately, this wouldn't leave room in the address space for anything
else. But this is just a matter of size. The complete table of 4-bit by 4-bit
sums occupies only 256 addresses. This leads to a workable approach: do two
separate 4-bit additions, one between the low 4 bits of the input bytes, and
another between the high 4 bits. Incorporate the carry from the low addition
into the high one, and combine the two sums together into a full 8-bit
addition. This can be all accomplished by a series of subsequent lookups in
around 5KiB of tables included with the program.

<p>Given one of these tables, how can byte byte jump perform a lookup? On the
face of it, it seems like the source and destination addresses for any given
instruction are fixed. The trick is an old one: self-modifying code. Either
or both byte of the source address can be overwritten by a prior move
instruction. Specifically, if a table ranges from $xy00 to $xyFF, then
overwriting the low byte of the source address with the offset causes the
next instruction to perform an indexed lookup in that table.

<p>Conditional branches and the like can be achieved using a similar trick,
instead overwriting the jump part of the address instead of the source.

<p>The above technique works byte at a time, which gives obvious access to
two table sizes: 8-bit and 16-bit. However, no 16-bit tables can be used,
since they would consume the entire address space, leaving no room for the
program. A 12-bit table only occupies 4KiB of the address space, which is
quite practical, and it would allow combining 4 bits of one index byte with
all 8 bits of another. This is the only way I could find for this
architecture to do a lookup that depended on more than one byte. This is
quite indispensible for doing addition, since our approach depends on adding
parts of two different bytes together.

<p>The trick is, of course, another table: this time to generate the high
byte of a 16-bit indexed lookup. The observation is that since we want 12-bit
tables, only the low 4 bits of the high byte should be allowed to vary with
the index. Another 8-bit table can overwrite the high 4 bits of any byte with
the highest 4 bits of the table address. This allows the low 4 bits of any
byte to offset a lookup in a 4096-byte table.

<p>Addition tables like the one used here are not purely theoretical; the
approach was used in at least one production computer. The <a
href="https://en.wikipedia.org/wiki/IBM_1620">IBM 1620</a> was codenamed
CADET during devolpment; some in the user community suggested that this
acronym stood for "Can't Add, Doesn't Even Try". But, even machines like
these can't add, they sure do a good impression of those that can!

<h2>Implementation</h2>

<h3>CPU Registers</h3>

<p>What would a hardware implementation of byte byte jump look like? Recall
the definition of the operation:

<ol>
    <li>Read the source, destination and jump addresses at the CPU's instruction pointer.
    <li>Read the byte at the source address and write it to the destination address.
    <li>Change the processor's instruction pointer to the jump address.
</ol>

<p>Incorporating a bit more detail into how the CPU communicates with the
system gives the following:

<ol>
    <li>Execute a system read operation using the CPU's instruction pointer.
    Save the 48 bits read from the system somewhere inside the processor.
    Store some of the bits as the new instruction pointer, and the others in
    CPU registers for the source and destination addresses.
    <li>Execute a system read operation at the source address, and save next
    8 bits in a location for the source value.
    <li>Execute a system write operation at the destination address and
    provide the 8 source value bits.
</ol>

<p>In the above, assume that the system can provide more than one byte's
worth of data per read. This simplifies things quite a bit, since there's no
need for the CPU to contain counting logic to generate subsequent addresses.
All of the provided address can be regurgitated back from the exact values
provided by the system.

<p>To produce the above set of reads and writes, the CPU needs to remember
around 56 bits of information. Tweaking the set of reads and writes can
probably bring this number down, but not any lower than 32, since the CPU
must maintain its instruction pointer at all times, and any read or write
requires remembering the 16-bit address. Right off the bat, if the CPU's
registers are accessed in a parallel fashion, we'll need at least 16 wires to
connect things up. Tons of breadboard space, tons of wires and connections to
route. Yuck, not simple.

<p>Instead of using parallel access then, how about serial? If the system
sends and receives data one bit at a time, then the CPU could do the same for
its internal storage. This would allow all 56 bits to be sent and received
over the same wire, just at different times, and the CPU could pass the
serial signal through to a serial storage chip inside itself. Seems like it
might be simpler.

<h3>Shopping</h3>

<p>So, we're now looking for a memory or register chip that communicates in a
serial fashion. To the store! I'll use <a
href="https://mouser.com">Mouser</a>, since I like their product filtering
UI. The chip needs to communicate serially, operate at 3.3 V, and ideally be
as cheap as possible. Oh, and mount using through-hole pins, so they're easy
to put on a breadboard.

<p>The cheapest memory chips there are EEPROM chips, but these are difficult
and slow to write to. We can filter those out. After that, the cheapest are
Flash chips; these are just fancy EEPROMs. To the bin with you!

<p>After filtering the various ROMs out, the next cheapest chip is the <a
href="https://www.microchip.com/wwwproducts/en/23K640">Microchip
23K640-I/P</a> 64KBit SRAM. This one communicates using the <a
href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface">Serial
Peripheral Interface</a> (SPI). SPI is just about the simplest serial
communications protocol I can imagine; this bodes well.

<h3>Microchip SRAM</h3>
<p>Looking at the <a
href="http://ww1.microchip.com/downloads/en/DeviceDoc/22126E.pdf">data
sheet</a> for this chip, the chip has 7 connected pins; that's good, not too
much to wire up. Besides power and ground, this leaves 5 data pins: <span
class="not">CS</span>, <span class="not">HOLD</span>, SCK, SI, and SO. The
overline indicates that the pin is "active" when it sees ground, not power. We say
that power voltage is "high" and that ground voltage is "low"; thus overlined pins
are "active low."

<p>During normal operation, shortly after SCK (serial clock) goes from ground
voltage (high) to power voltage, the chip samples the voltage level of the SI
(serial input) pin. If the voltage level is power, the chip considers itself
to have read a one; ground, a zero. Shortly after SCK returns from power
voltage to ground voltage, the chip has the opportunity to output a bit on
SO. It does so by internally connecting SO to either power for a one or
ground for a zero. If it does not desire to output a bit, it leaves SO
disconnected.

<p>In the usual configuration SCK is always ticking, but a read or write
needs to have a definite beginning and ending. This is the purpose of the
<span class="not">CS</span> (chip select) pin. When <span
class="not">CS</span> is high, the chip is blind to SCK ticks, and SO is
disconnected. When <span class="not">CS</span> transitions from high to low,
the chip considers an operation to have begun; when <span
class="not">CS</span> transitions back from low to high, the operation ends.
All values sent in and out of the chip are most-significant-bit first.

<p>There are two basic operation cycles: read and write. A read operation
consists of clocking 00000011 to the chip, then the 16-bit address.
Afterwards, the chip will clock the byte at that address to SO. By
default, it's unspecified what happens if the operation is not immediately
ended after one byte.

<p>A write operation consists of clocking 00000010 to the chip, then the
16-bit address, then the byte to write. By default, it's unspecified what
happens if the operation is not immediately ended after one byte.

<p>Writing one byte at a time isn't exactly ideal, since we'd need the
aforementioned counting mechanism to generate successive accesses. Luckily,
the chip provides a "sequential mode", which operates very much as we'd
desire. In sequential mode, as many bytes as desired can be read or written
by continuing the operation after the first bytes. The chip does not
initialize in sequential mode however; an operation needs to be executed to
place the chip in this mode.

<p>Man, wouldn't it be nice if the chip started in sequential mode? Then we
wouldn't have to deal with this extra operation; just read and write. Well,
if we go a bit up in Microchip's SRAM product line to the 23LC512, we find a
512KBit (64KiB) SRAM that operations almost identically to the 23K640. This
larger chip defaults to sequential mode, and still only costs around a buck!

<h4>Aside</h4>

<p>I'll pause for a moment to revel in the decision to use a 64KiB SRAM to
store 56 bits of data inside a CPU. This chip probably has far more switching
elements in it than the first 100 computers built by man. Still, the magic of
VLSI makes this the simplest and most cost effective option for this storage.

<p>Though this chip does have an instruction set and sequential control
logic for executing it, it's far from Turing complete on its own. It doesn't
have the, for lack of a better word, recursiveness required for general
computation. Our goal will then be to bless it with this recursiveness, by
reflecting some aspects of its own operation back at it, to turn it from a
simple RAM chip into a fully fledged CPU.

<h3>Microcode</h3>

<p>Now that we have a real chip to work with, we can recast the orignal list of
tasks in terms of the chip. Zero seems the most natural address at which to
store data in the SRAM.

<ol>
  <li>Read the instruction.
    <ol>
        <li>Activate chip. Begin system read.
        <li>Send 00000011 (read) to SI.
        <li>Send the instruction pointer's address in the register memory to SI.
        <li>The chip sends the instruction pointer to the system via SO.
        <li>Deactivate chip.
        <li>Activate chip.
        <li>Send 00000010 (write) to SI.
        <li>Send the address that will receive the instruction to SI. The jump
        address overlaps the instruction pointer in the SRAM.
        <li>The system sends 48 bits of data to the chip via SI. This overwrites
        the instruction pointer as well.
        <li>End system read. Deactivate chip.
    </ol>
  <li>Read the value at the source address.
    <ol>
      <li>Activate chip. Begin system read.
      <li>Send 00000011 (read) to SI.
      <li>Send the source address's address in the register memory to SI.
      <li>The chip sends the source address to the system via SO.
      <li>Deactivate chip.
      <li>Activate chip.
      <li>Send 00000010 (write) to SI.
      <li>Send the address that will receive the source value to SI.
      <li>The system sends 8 bits of data to the chip via SI.
      <li>End system read. Deactivate chip.
    </ol>
  <li>Store the value at the destination address.
    <ol>
      <li>Activate chip. Begin system write.
      <li>Send 00000011 (read) to SI.
      <li>Send the destination address's address in the register memory to SI.
      <li>The chip sends the destination address to the system via SO.
      <li>Deactivate chip.
      <li>Activate chip.
      <li>Send 00000011 (read) to SI.
      <li>Send the address that received the source value to SI.
      <li>The chip sends 8 bits of data to the system via SO.
      <li>End system read. Deactivate chip.
    </ol>
</ol>

<p>Some immediate observations spring from the above breakdown. First, SI and
SO never have signals sent across them at the same time. This means they can
be physically connected together into one SIO signal; this is referred to as
"three wire SPI." This means all data passes over one wire, whether driven by
control, the bus, or the SRAM chip.

<p>Next, the layout of the SRAM and instruction can be specified. For
simplicity, let's begin the used region of the SRAM at address zero. The
instruction pointer is the first value accessed, so place that at zero. Then,
beginning each instruction with the instruction pointer establishes the
overlap criterion of 1.8 and 1.9. If the value ends with the destination
address, then the value location can follow immediately afterwards. This
saves the second read cycle at 3.7, which can be skipped by allowing the chip
to read from the destination address straight through to the value.

<p>No explicit mechanism for controlling the system bus has been established.
We can crib a simplified mechanism for this from our SRAM. Give the system
bus an active low select line, just like the chip. Read and write operations
work exactly as on the chip, except a read is signalled by writing a 0, and a
write by writing a 1.

<p>Putting that all together, we get the following:

<ol>
  <li>Read the instruction.
    <ol>
        <li>Activate system.
        <li>Send 0.
        <li>Activate chip.
        <li>Send 00000011.
        <li>Send the instruction pointer's address.
        <li>The chip sends the instruction pointer.
        <li>Deactivate chip.
        <li>Activate chip.
        <li>Send 00000010.
        <li>Send the address that will receive the instruction.
        <li>The system sends 48 bits of data.
        <li>Deactivate system. Deactivate chip.
    </ol>
  <li>Read the value at the source address.
    <ol>
      <li>Activate system.
      <li>Send 0.
      <li>Activate chip.
      <li>Send 00000011.
      <li>Send the source address's address.
      <li>The chip sends the source address.
      <li>Deactivate chip.
      <li>Activate chip.
      <li>Send 00000010.
      <li>Send the source value's address.
      <li>The system sends 8 bits of data.
      <li>Deactivate system. Deactivate chip.
    </ol>
  <li>Store the value at the destination address.
    <ol>
      <li>Activate system.
      <li>Send 1.
      <li>Activate chip.
      <li>Send 00000011.
      <li>Send the destination address's address.
      <li>The chip sends 24 bits of data.
      <li>Deactivate system. Deactivate chip.
    </ol>
</ol>

<h3>Main Cycle</h3>

<pre>
-- Read instruction from SIO into R
  -- Begin read (0) on SIO
  !CS = 0; SIO.!HOLD = 1; SIO = 0

  -- Begin read of IP (0) on R
  6 R.!CS = 0; SIO = 0
  
  16 SIO = 0

  -- R sends instruction address (*IP) to SIO
  16 SIO.!HOLD = 0
  R.!CS = 1

  -- Begin write of IP (0) on R
  6 R.!CS = 0; SIO.!HOLD = 1; SIO = 0
  SIO = 1
  SIO = 0
  16 SIO = 0

  -- SIO sends instruction to R
  48 SIO.!HOLD = 0
  R.!CS = 1; !CS = 1

-- Read value from SIO into R
  -- Begin read (0) on SIO
  !CS = 0; SIO.!HOLD = 1; SIO = 0

  -- Begin read of SRC (2) on R
  6 R.!CS = 0; SIO = 0
  2 SIO = 1
  14 SIO = 0
  SIO = 1
  SIO = 0

  -- R sends source address to SIO
  16 SIO.!HOLD = 0
  R.!CS = 1

  -- Begin write of VAL (6) on R
  6 R.!CS = 0; SIO.!HOLD = 1; SIO = 0
  SIO = 1
  SIO = 0
  13 SIO = 0
  2 SIO = 1
  SIO = 0

  -- SIO sends value to R
  8 SIO.!HOLD = 0
  R.!CS = 1; !CS = 1

-- Write value from R to SIO
  -- Begin write (1) on SIO
  !CS = 0; SIO.!HOLD = 1; SIO = 1

  -- Begin read of DST (4) on R
  6 R.!CS = 0; SIO = 0
  2 SIO = 1
  13 SIO = 0
  SIO = 1
  2 SIO = 0

  -- R sends destination address and value to SIO
  24 SIO.!HOLD = 0
  R.!CS = 1; !CS = 1
</pre>

In total, 240 cycles. Not too shabby!

<h3>Main Cycle for R.!CS</h3>
<pre>
  R.!CS = 1
  40 R.!CS = 0
  R.!CS = 1
  72 R.!CS = 0
  2 R.!CS = 1
  40 R.!CS = 0
  R.!CS = 1
  32 R.!CS = 0
  2 R.!CS = 1
  48 R.!CS = 0
  R.!CS = 1
</pre>

<h3>Main Cycle for !CS</h3>
<pre>
  114 !CS = 0
  !CS = 1
  74 !CS = 0
  !CS = 1
  49 !CS = 0
  !CS = 1
</pre>

<h3>Main Cycle for SIO</h3>
This includes the effect of the SIO.!HOLD signal, since this EEPROM is held for those cycles.
<pre>
  7 SIO = 0
  2 SIO = 1
  22 SIO = 0
  SIO = 1
  24 SIO = 0
  2 SIO = 1
  14 SIO = 0
  SIO = 1
  7 SIO = 0
  SIO = 1
  14 SIO = 0
  2 SIO = 1
  SIO = 0
  SIO = 1
  6 SIO = 0
  2 SIO = 1
  13 SIO = 0
  SIO = 1
  2 SIO = 0
</pre>

<h3>Main Cycle for SIO.!HOLD</h3>
<pre>
  25 SIO.!HOLD = 1
  17 SIO.!HOLD = 0
  24 SIO.!HOLD = 1
  49 SIO.!HOLD = 0
  25 SIO.!HOLD = 1
  17 SIO.!HOLD = 0
  24 SIO.!HOLD = 1
  9 SIO.!HOLD = 0
  25 SIO.!HOLD = 1
  25 SIO.!HOLD = 0
</pre>

<h3>Cycle Placement</h3>
<p>Since the main processor cycle takes 240 clock cycles, a 1024-bit EEPROM
can contain 4 main cycles. Since the SIO cycle is held for 117 of these
cycles, it only takes 123 cycles, and the 1024-bit EEPROM could
hypothetically hold 8 of them. However, in both cases there would be a
remainder of bits left over, since neither number evenly divides into 1024.
We need the two types of EEPROM to stay in sync with one another as these
remainders are handled.

<p>The 123 SIO cycles will fit 4 times into 512 bits, which allows the SIO
EEPROM to service 8 main processor cycles with SIO bits. There are 512 -
4*123 = 20 bits left over on the SIO EEPROM and 1024 - 4*240 = 64 bits left
over on the main EEPROMS. We thus need to hold the SIO eeprom for 64-20 = 44
cycles to sync the two EEPROMS up once every 4 cycles. These hold bits can be
placed anywhere in the empty region following the main cycle at the very end
of the SIO.!HOLD EEPROM.
</div>